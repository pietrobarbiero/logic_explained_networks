{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import trange\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "from lens.models.tree import XDecisionTreeClassifier\n",
    "from lens.models.anchors import XAnchorClassifier\n",
    "from lens.models.random_forest import XRandomForestClassifier\n",
    "from lens.utils.base import set_seed, ClassifierNotTrainedError, IncompatibleClassifierError\n",
    "from lens.utils.metrics import Accuracy, F1Score\n",
    "from lens.models import XMuNN, XPsiNetwork, XReluNN\n",
    "from lens.utils.datasets import StructuredDataset\n",
    "from lens.logic.base import test_explanation\n",
    "from lens.logic.metrics import complexity, fidelity, formula_consistency\n",
    "from data import MIMIC\n",
    "from data.load_structured_datasets import load_mimic\n",
    "\n",
    "results_dir = 'results/mimic'\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading MIMIC data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/\n",
      "Number of features 90\n",
      "Concept names ['aline_flg', 'gender_num', 'sepsis_flg', 'chf_flg', 'afib_flg', 'renal_flg', 'liver_flg', 'copd_flg', 'cad_flg', 'stroke_flg', 'mal_flg', 'resp_flg', 'abg_count_LOW', 'abg_count_NORMAL', 'abg_count_HIGH', 'age_LOW', 'age_NORMAL', 'age_HIGH', 'bmi_LOW', 'bmi_NORMAL', 'bmi_HIGH', 'bun_first_LOW', 'bun_first_NORMAL', 'bun_first_HIGH', 'chloride_first_LOW', 'chloride_first_NORMAL', 'chloride_first_HIGH', 'creatinine_first_LOW', 'creatinine_first_NORMAL', 'creatinine_first_HIGH', 'day_icu_intime_num_LOW', 'day_icu_intime_num_NORMAL', 'day_icu_intime_num_HIGH', 'hgb_first_LOW', 'hgb_first_NORMAL', 'hgb_first_HIGH', 'hour_icu_intime_LOW', 'hour_icu_intime_NORMAL', 'hour_icu_intime_HIGH', 'hr_1st_LOW', 'hr_1st_NORMAL', 'hr_1st_HIGH', 'icu_los_day_LOW', 'icu_los_day_NORMAL', 'icu_los_day_HIGH', 'iv_day_1_LOW', 'iv_day_1_NORMAL', 'iv_day_1_HIGH', 'map_1st_LOW', 'map_1st_NORMAL', 'map_1st_HIGH', 'pco2_first_LOW', 'pco2_first_NORMAL', 'pco2_first_HIGH', 'platelet_first_LOW', 'platelet_first_NORMAL', 'platelet_first_HIGH', 'po2_first_LOW', 'po2_first_NORMAL', 'po2_first_HIGH', 'potassium_first_LOW', 'potassium_first_NORMAL', 'potassium_first_HIGH', 'sapsi_first_LOW', 'sapsi_first_NORMAL', 'sapsi_first_HIGH', 'service_num_LOW', 'service_num_NORMAL', 'service_num_HIGH', 'sodium_first_LOW', 'sodium_first_NORMAL', 'sodium_first_HIGH', 'sofa_first_LOW', 'sofa_first_NORMAL', 'sofa_first_HIGH', 'spo2_1st_LOW', 'spo2_1st_NORMAL', 'spo2_1st_HIGH', 'tco2_first_LOW', 'tco2_first_NORMAL', 'tco2_first_HIGH', 'temp_1st_LOW', 'temp_1st_NORMAL', 'temp_1st_HIGH', 'wbc_first_LOW', 'wbc_first_NORMAL', 'wbc_first_HIGH', 'weight_first_LOW', 'weight_first_NORMAL', 'weight_first_HIGH']\n",
      "Class names ['death_before_28_days', 'survived_28_days']\n"
     ]
    }
   ],
   "source": [
    "dataset_root = \"../data/\"\n",
    "dataset_name = MIMIC\n",
    "print(dataset_root)\n",
    "x, y, concept_names, class_names = load_mimic(dataset_root)\n",
    "y = y.argmax(dim=1)\n",
    "dataset = StructuredDataset(x, y, dataset_name=dataset_name, feature_names=concept_names, class_names=class_names)\n",
    "n_features = x.shape[1]\n",
    "n_classes = len(class_names)\n",
    "print(\"Number of features\", n_features)\n",
    "print(\"Concept names\", concept_names)\n",
    "print(\"Class names\", class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define loss, metrics and methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methods ['Anchors', 'DTree', 'Psi', 'Relu', 'General']\n"
     ]
    }
   ],
   "source": [
    "loss = CrossEntropyLoss()\n",
    "metric = Accuracy()\n",
    "expl_metric = F1Score()\n",
    "method_list = ['Anchors', 'DTree', 'Psi', 'Relu', 'Mu']  # 'BRL', 'DeepRed']\n",
    "print(\"Methods\", method_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\owl\\AppData\\Local\\JetBrains\\PyCharm 2021.1.3\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_utils.py\", line 69, in attach_to_debugger\n",
      "    debugger.prepare_to_run(enable_tracing_from_start=False)\n",
      "TypeError: prepare_to_run() got an unexpected keyword argument 'enable_tracing_from_start'\n",
      "Failed to connect to target debugger.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Device cpu\n",
      "Training results/mimic\\Anchors_0 classifier...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 14>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     62\u001B[0m         exp_fidelities\u001B[38;5;241m.\u001B[39mappend(exp_fidelity), exp_complexities\u001B[38;5;241m.\u001B[39mappend(explanation_complexity)\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAnchors\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 65\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mXAnchorClassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_classes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     67\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     68\u001B[0m         model\u001B[38;5;241m.\u001B[39mload(device)\n",
      "File \u001B[1;32m~\\Documents\\Scuola\\3_Dottorato\\Codice\\LENs\\lens\\models\\anchors.py:44\u001B[0m, in \u001B[0;36mXAnchorClassifier.__init__\u001B[1;34m(self, n_classes, n_features, train_dataset, device, name)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset \u001B[38;5;241m=\u001B[39m train_dataset\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m RandomForestClassifier(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[1;32m---> 44\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexplainer \u001B[38;5;241m=\u001B[39m \u001B[43mAnchorTabularExplainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclass_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_classes \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m     51\u001B[0m     n_classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\Scuola\\3_Dottorato\\Codice\\LENs\\lens\\models\\ext_models\\anchor\\anchor_tabular.py:49\u001B[0m, in \u001B[0;36mAnchorTabularExplainer.__init__\u001B[1;34m(self, class_names, feature_names, train_data, categorical_names, discretizer, encoder_fn)\u001B[0m\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcategorical_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(categorical_names\u001B[38;5;241m.\u001B[39mkeys())\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m discretizer \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquartile\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m---> 49\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdisc \u001B[38;5;241m=\u001B[39m \u001B[43mlime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlime_tabular\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mQuartileDiscretizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcategorical_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     51\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_names\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m discretizer \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdecile\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     53\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdisc \u001B[38;5;241m=\u001B[39m lime\u001B[38;5;241m.\u001B[39mlime_tabular\u001B[38;5;241m.\u001B[39mDecileDiscretizer(train_data,\n\u001B[0;32m     54\u001B[0m                                              \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcategorical_features,\n\u001B[0;32m     55\u001B[0m                                              \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_names)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\LogicExplainedTransformers\\lib\\site-packages\\lime\\discretize.py:178\u001B[0m, in \u001B[0;36mQuartileDiscretizer.__init__\u001B[1;34m(self, data, categorical_features, feature_names, labels, random_state)\u001B[0m\n\u001B[0;32m    176\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, data, categorical_features, feature_names, labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m--> 178\u001B[0m     \u001B[43mBaseDiscretizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcategorical_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    179\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    180\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\LogicExplainedTransformers\\lib\\site-packages\\lime\\discretize.py:64\u001B[0m, in \u001B[0;36mBaseDiscretizer.__init__\u001B[1;34m(self, data, categorical_features, feature_names, labels, random_state, data_stats)\u001B[0m\n\u001B[0;32m     62\u001B[0m n_bins \u001B[38;5;241m=\u001B[39m qts\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# Actually number of borders (= #bins-1)\u001B[39;00m\n\u001B[0;32m     63\u001B[0m boundaries \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmin(data[:, feature]), np\u001B[38;5;241m.\u001B[39mmax(data[:, feature])\n\u001B[1;32m---> 64\u001B[0m name \u001B[38;5;241m=\u001B[39m \u001B[43mfeature_names\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfeature\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnames[feature] \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m <= \u001B[39m\u001B[38;5;132;01m%.2f\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m (name, qts[\u001B[38;5;241m0\u001B[39m])]\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_bins \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m):\n",
      "\u001B[1;31mIndexError\u001B[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "n_processes = 1\n",
    "timeout = 6 * 60 * 60  # 1 h timeout\n",
    "l_r = 1e-4\n",
    "lr_scheduler = False\n",
    "top_k_explanations = 20\n",
    "simplify = True\n",
    "seeds = [*range(10)]  # [*range(5)]\n",
    "print(\"Seeds\", seeds)\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Device\", device)\n",
    "\n",
    "for method in method_list:\n",
    "\n",
    "    methods = []\n",
    "    splits = []\n",
    "    model_explanations = []\n",
    "    model_accuracies = []\n",
    "    explanation_accuracies = []\n",
    "    elapsed_times = []\n",
    "    explanation_fidelities = []\n",
    "    explanation_complexities = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=len(seeds), shuffle=True, random_state=0)\n",
    "\n",
    "    for seed, (trainval_index, test_index) in enumerate(skf.split(x.numpy(), y.numpy())):\n",
    "        if seed >= 5:\n",
    "            break\n",
    "        set_seed(seed)\n",
    "        x_trainval, y_trainval = x[trainval_index], y[trainval_index]\n",
    "        x_test, y_test = x[test_index], y[test_index]\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_trainval, y_trainval, test_size=0.3, random_state=0)\n",
    "        train_data = StructuredDataset(x_train, y_train, dataset_name, concept_names, class_names)\n",
    "        val_data = StructuredDataset(x_val, y_val, dataset_name, concept_names, class_names)\n",
    "        test_data = StructuredDataset(x_test, y_test, dataset_name, concept_names, class_names)\n",
    "\n",
    "        name = os.path.join(results_dir, f\"{method}_{seed}\")\n",
    "\n",
    "        # Setting device\n",
    "        print(f\"Training {name} classifier...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        if method == 'DTree':\n",
    "            model = XDecisionTreeClassifier(name=name, n_classes=n_classes,\n",
    "                                            n_features=n_features, max_depth=5)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                model.fit(train_data, val_data, metric=metric, save=True)\n",
    "            outputs, labels = model.predict(test_data, device=device)\n",
    "            accuracy = model.evaluate(test_data, metric=metric, outputs=outputs, labels=labels)\n",
    "            explanations, exp_accuracies, exp_fidelities, exp_complexities = [], [], [], []\n",
    "            for i in trange(n_classes, desc=f\"{method} extracting explanations\"):\n",
    "                explanation = model.get_global_explanation(i, concept_names)\n",
    "                exp_accuracy, exp_predictions = test_explanation(explanation, i, x_test, y_test, metric=expl_metric,\n",
    "                                                                 concept_names=concept_names, inequalities=True)\n",
    "                exp_fidelity = 100\n",
    "                explanation_complexity = complexity(explanation)\n",
    "                explanations.append(explanation), exp_accuracies.append(exp_accuracy)\n",
    "                exp_fidelities.append(exp_fidelity), exp_complexities.append(explanation_complexity)\n",
    "\n",
    "        elif method == \"Anchors\":\n",
    "            model = XAnchorClassifier(n_classes, n_features,\n",
    "                                      train_data, name=name)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                model.fit(train_data, val_data, metric=metric, save=True)\n",
    "            outputs, labels = model.predict(test_data, device=device)\n",
    "            accuracy = model.evaluate(test_data, metric=metric, outputs=outputs, labels=labels)\n",
    "            explanations, exp_accuracies, exp_fidelities, exp_complexities = [], [], [], []\n",
    "            for i in trange(n_classes, desc=f\"{method} extracting explanations\"):\n",
    "                explanation = model.get_global_explanation(i, val_data)\n",
    "                exp_accuracy, exp_predictions = test_explanation(explanation, i, x_test, y_test, metric=expl_metric,\n",
    "                                                                 concept_names=concept_names, inequalities=True)\n",
    "                exp_fidelity = 100\n",
    "                explanation_complexity = complexity(explanation)\n",
    "                explanations.append(explanation), exp_accuracies.append(exp_accuracy)\n",
    "                exp_fidelities.append(exp_fidelity), exp_complexities.append(explanation_complexity)\n",
    "\n",
    "\n",
    "        # elif method == 'BRL':\n",
    "        #     train_sample_rate = 1.0\n",
    "        #     model = XBRLClassifier(name=name, n_classes=n_classes, n_features=n_features, n_processes=n_processes,\n",
    "        #                            feature_names=concept_names, class_names=class_names, discretize=True)\n",
    "        #     try:\n",
    "        #         model.load(device)\n",
    "        #         print(f\"Model {name} already trained\")\n",
    "        #     except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "        #         model.fit(train_data, metric=metric, train_sample_rate=train_sample_rate, verbose=False, eval=False)\n",
    "        #     outputs, labels = model.predict(test_data, device=device)\n",
    "        #     accuracy = model.evaluate(test_data, metric=metric, outputs=outputs, labels=labels)\n",
    "        #     explanations, exp_accuracies, exp_fidelities, exp_complexities = [], [], [], []\n",
    "        #     for i in trange(n_classes, desc=f\"{method} extracting explanations\"):\n",
    "        #         explanation = model.get_global_explanation(i, concept_names)\n",
    "        #         exp_accuracy, exp_predictions = test_explanation(explanation, i, x_test, y_test, metric=expl_metric,\n",
    "        #                                                          concept_names=concept_names)\n",
    "        #         exp_fidelity = 100\n",
    "        #         explanation_complexity = complexity(explanation, to_dnf=True)\n",
    "        #         explanations.append(explanation), exp_accuracies.append(exp_accuracy)\n",
    "        #         exp_fidelities.append(exp_fidelity), exp_complexities.append(explanation_complexity)\n",
    "\n",
    "        # elif method == 'DeepRed':\n",
    "        #     train_sample_rate = 1.0\n",
    "        #     model = XDeepRedClassifier(n_classes, n_features, name=name)\n",
    "        #     model.prepare_data(dataset, dataset_name, seed, trainval_index, test_index, train_sample_rate)\n",
    "        #     try:\n",
    "        #         model.load(device)\n",
    "        #         print(f\"Model {name} already trained\")\n",
    "        #     except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "        #         model.fit(epochs=epochs, seed=seed, metric=metric)\n",
    "        #     outputs, labels = model.predict(train=False, device=device)\n",
    "        #     accuracy = model.evaluate(train=False, metric=metric, outputs=outputs, labels=labels)\n",
    "        #     explanations, exp_accuracies, exp_fidelities, exp_complexities = [], [], [], []\n",
    "        #     print(\"Extracting rules...\")\n",
    "        #     t = time.time()\n",
    "        #     for i in trange(n_classes, desc=f\"{method} extracting explanations\"):\n",
    "        #         explanation = model.get_global_explanation(i, concept_names, simplify=simplify)\n",
    "        #         exp_accuracy, exp_predictions = test_explanation(explanation, i, x_test, y_test,\n",
    "        #                                                          metric=expl_metric,\n",
    "        #                                                          concept_names=concept_names, inequalities=True)\n",
    "        #         exp_predictions = torch.as_tensor(exp_predictions)\n",
    "        #         class_output = torch.as_tensor(outputs.argmax(dim=1) == i)\n",
    "        #         exp_fidelity = fidelity(exp_predictions, class_output, expl_metric)\n",
    "        #         explanation_complexity = complexity(explanation)\n",
    "        #         explanations.append(explanation), exp_accuracies.append(exp_accuracy)\n",
    "        #         exp_fidelities.append(exp_fidelity), exp_complexities.append(explanation_complexity)\n",
    "        #         print(f\"{i + 1}/{n_classes} Rules extracted. Time {time.time() - t}\")\n",
    "\n",
    "        elif method == 'Psi':\n",
    "            # Network structures\n",
    "            l1_weight = 1e-4\n",
    "            hidden_neurons = [10, 5]\n",
    "            fan_in = 3\n",
    "            lr_psi = 1e-2\n",
    "            print(\"L1 weight\", l1_weight)\n",
    "            print(\"Hidden neurons\", hidden_neurons)\n",
    "            print(\"Fan in\", fan_in)\n",
    "            name = os.path.join(results_dir, f\"{method}_{seed}_{l1_weight}_{hidden_neurons}_{fan_in}_{lr_psi}\")\n",
    "            model = XPsiNetwork(n_classes, n_features, hidden_neurons, loss, l1_weight, name=name, fan_in=fan_in)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                model.fit(train_data, val_data, epochs=epochs, l_r=lr_psi, verbose=True,\n",
    "                          metric=metric, lr_scheduler=lr_scheduler, device=device, save=True)\n",
    "            outputs, labels = model.predict(test_data, device=device)\n",
    "            accuracy = model.evaluate(test_data, metric=metric, outputs=outputs, labels=labels)\n",
    "            explanations, exp_accuracies, exp_fidelities, exp_complexities = [], [], [], []\n",
    "            for i in trange(n_classes, desc=f\"{method} extracting explanations\"):\n",
    "                explanation = model.get_global_explanation(i, concept_names, simplify=simplify, x_train=x_train)\n",
    "                exp_accuracy, exp_predictions = test_explanation(explanation, i, x_test, y_test,\n",
    "                                                                 metric=expl_metric, concept_names=concept_names)\n",
    "                exp_predictions = torch.as_tensor(exp_predictions)\n",
    "                class_output = torch.as_tensor(outputs.argmax(dim=1) == i)\n",
    "                exp_fidelity = fidelity(exp_predictions, class_output, expl_metric)\n",
    "                explanation_complexity = complexity(explanation, to_dnf=True)\n",
    "                explanations.append(explanation), exp_accuracies.append(exp_accuracy)\n",
    "                exp_fidelities.append(exp_fidelity), exp_complexities.append(explanation_complexity)\n",
    "\n",
    "        elif method == 'Mu':\n",
    "            # Network structures\n",
    "            l1_weight = 1e-4\n",
    "            hidden_neurons = [100, 30, 10]\n",
    "            fan_in = 5\n",
    "            top_k_explanations = None\n",
    "            name = os.path.join(results_dir, f\"{method}_{seed}_{l1_weight}_{hidden_neurons}_{fan_in}\")\n",
    "            model = XMuNN(n_classes=n_classes, n_features=n_features, hidden_neurons=hidden_neurons,\n",
    "                               loss=loss, name=name, l1_weight=l1_weight, fan_in=fan_in)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                model.fit(train_data, val_data, epochs=epochs, l_r=l_r, metric=metric,\n",
    "                          lr_scheduler=lr_scheduler, device=device, save=True, verbose=True)\n",
    "            outputs, labels = model.predict(test_data, device=device)\n",
    "            accuracy = model.evaluate(test_data, metric=metric, outputs=outputs, labels=labels)\n",
    "            explanations, exp_accuracies, exp_fidelities, exp_complexities = [], [], [], []\n",
    "            for i in trange(n_classes, desc=f\"{method} extracting explanations\"):\n",
    "                explanation = model.get_global_explanation(x_train, y_train, i, top_k_explanations=top_k_explanations,\n",
    "                                                           concept_names=concept_names, simplify=simplify,\n",
    "                                                           metric=expl_metric, x_val=x_val, y_val=y_val)\n",
    "                exp_accuracy, exp_predictions = test_explanation(explanation, i, x_test, y_test,\n",
    "                                                                 metric=expl_metric, concept_names=concept_names)\n",
    "                exp_predictions = torch.as_tensor(exp_predictions)\n",
    "                class_output = torch.as_tensor(outputs.argmax(dim=1) == i)\n",
    "                exp_fidelity = fidelity(exp_predictions, class_output, expl_metric)\n",
    "                explanation_complexity = complexity(explanation)\n",
    "                explanations.append(explanation), exp_accuracies.append(exp_accuracy)\n",
    "                exp_fidelities.append(exp_fidelity), exp_complexities.append(explanation_complexity)\n",
    "\n",
    "        elif method == 'Relu':\n",
    "            # Network structures\n",
    "            l1_weight = 1e-4\n",
    "            hidden_neurons = [100, 50, 30, 10]\n",
    "            dropout_rate = 0.3\n",
    "            print(\"l1 weight\", l1_weight)\n",
    "            print(\"hidden neurons\", hidden_neurons)\n",
    "            model = XReluNN(n_classes=n_classes, n_features=n_features, name=name, dropout_rate=dropout_rate,\n",
    "                            hidden_neurons=hidden_neurons, loss=loss, l1_weight=l1_weight)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                model.fit(train_data, val_data, epochs=epochs, l_r=l_r, verbose=True,\n",
    "                          metric=metric, lr_scheduler=lr_scheduler, device=device, save=True)\n",
    "            outputs, labels = model.predict(test_data, device=device)\n",
    "            accuracy = model.evaluate(test_data, metric=metric, outputs=outputs, labels=labels)\n",
    "            explanations, exp_accuracies, exp_fidelities, exp_complexities = [], [], [], []\n",
    "            for i in trange(n_classes, desc=f\"{method} extracting explanations\"):\n",
    "                explanation = model.get_global_explanation(x_train, y_train, i,\n",
    "                                                           top_k_explanations=top_k_explanations,\n",
    "                                                           concept_names=concept_names,\n",
    "                                                           metric=expl_metric, x_val=x_val, y_val=y_val)\n",
    "                exp_accuracy, exp_predictions = test_explanation(explanation, i, x_test, y_test,\n",
    "                                                                 metric=expl_metric, concept_names=concept_names)\n",
    "                exp_predictions = torch.as_tensor(exp_predictions)\n",
    "                class_output = torch.as_tensor(outputs.argmax(dim=1) == i)\n",
    "                exp_fidelity = fidelity(exp_predictions, class_output, expl_metric)\n",
    "                explanation_complexity = complexity(explanation)\n",
    "                explanations.append(explanation), exp_accuracies.append(exp_accuracy)\n",
    "                exp_fidelities.append(exp_fidelity), exp_complexities.append(explanation_complexity)\n",
    "\n",
    "        elif method == 'RandomForest':\n",
    "            set_seed(seed)\n",
    "            model = XRandomForestClassifier(name=name, n_classes=n_classes,\n",
    "                                            n_features=n_features)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                model.fit(train_data, val_data, epochs=epochs, l_r=l_r, metric=metric,\n",
    "                          lr_scheduler=lr_scheduler, device=device, save=True, verbose=True)\n",
    "            accuracy = model.evaluate(test_data, metric=metric)\n",
    "            explanations, exp_accuracies, exp_fidelities, exp_complexities = [\"\"], [0], [0], [0]\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError(f\"{method} not implemented\")\n",
    "\n",
    "        if model.time is None:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            # In BRL the training is parallelized to speed up operation\n",
    "            if method == \"BRL\":\n",
    "                elapsed_time = elapsed_time * n_processes\n",
    "            model.time = elapsed_time\n",
    "            # To save the elapsed time and the explanations\n",
    "            model.save(device)\n",
    "        else:\n",
    "            elapsed_time = model.time\n",
    "\n",
    "        # Restore original folder\n",
    "        if method == \"DeepRed\":\n",
    "            model.finish()\n",
    "\n",
    "        methods.append(method)\n",
    "        splits.append(seed)\n",
    "        model_explanations.append(explanations[0])\n",
    "        model_accuracies.append(accuracy)\n",
    "        elapsed_times.append(elapsed_time)\n",
    "        explanation_accuracies.append(np.mean(exp_accuracies))\n",
    "        explanation_fidelities.append(np.mean(exp_fidelities))\n",
    "        explanation_complexities.append(np.mean(exp_complexities))\n",
    "        print(\"Test model accuracy\", accuracy)\n",
    "        print(\"Explanation time\", elapsed_time)\n",
    "        print(\"Explanation accuracy mean\", np.mean(exp_accuracies))\n",
    "        print(\"Explanation fidelity mean\", np.mean(exp_fidelities))\n",
    "        print(\"Explanation complexity mean\", np.mean(exp_complexities))\n",
    "\n",
    "    explanation_consistency = formula_consistency(model_explanations)\n",
    "    print(f'Consistency of explanations: {explanation_consistency:.4f}')\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'method': methods,\n",
    "        'split': splits,\n",
    "        'explanation': model_explanations,\n",
    "        'model_accuracy': model_accuracies,\n",
    "        'explanation_accuracy': explanation_accuracies,\n",
    "        'explanation_fidelity': explanation_fidelities,\n",
    "        'explanation_complexity': explanation_complexities,\n",
    "        'explanation_consistency': [explanation_consistency] * len(splits),\n",
    "        'elapsed_time': elapsed_times,\n",
    "    })\n",
    "    results.to_csv(os.path.join(results_dir, f'results_{method}.csv'))\n",
    "    print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols = ['model_accuracy', 'explanation_accuracy', 'explanation_fidelity', 'explanation_complexity', 'elapsed_time',\n",
    "        'explanation_consistency']\n",
    "mean_cols = [f'{c}_mean' for c in cols]\n",
    "sem_cols = [f'{c}_sem' for c in cols]\n",
    "\n",
    "results_df = {}\n",
    "summaries = {}\n",
    "for m in method_list:\n",
    "    results_df[m] = pd.read_csv(os.path.join(results_dir, f\"results_{m}.csv\"))\n",
    "    df_mean = results_df[m][cols].mean()\n",
    "    df_sem = results_df[m][cols].sem()\n",
    "    df_mean.columns = mean_cols\n",
    "    df_sem.columns = sem_cols\n",
    "    summaries[m] = pd.concat([df_mean, df_sem])\n",
    "    summaries[m].name = m\n",
    "\n",
    "results_df = pd.concat([results_df[method] for method in method_list])\n",
    "results_df.to_csv(os.path.join(results_dir, f'results_{method_list}.csv'))\n",
    "\n",
    "summary = pd.concat([summaries[method] for method in method_list], axis=1).T\n",
    "summary.columns = mean_cols + sem_cols\n",
    "summary.to_csv(os.path.join(results_dir, f'summary_{method_list}.csv'))\n",
    "print(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-b0a6d04e",
   "language": "python",
   "display_name": "PyCharm (LETs)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}