{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sympy import simplify_logic\n",
    "\n",
    "from deep_logic.utils.relunn import get_reduced_model, prune_features\n",
    "from deep_logic import fol\n",
    "from deep_logic.utils.base import collect_parameters\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression_matrix = pd.read_csv('w_1/data_0.csv', index_col=None, header=None)\n",
    "labels = pd.read_csv('w_1/tempLabels_W-1.csv', index_col=None, header=None)\n",
    "genes = pd.read_csv('w_1/features_0.csv', index_col=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28392</th>\n",
       "      <th>28393</th>\n",
       "      <th>28394</th>\n",
       "      <th>28395</th>\n",
       "      <th>28396</th>\n",
       "      <th>28397</th>\n",
       "      <th>28398</th>\n",
       "      <th>28399</th>\n",
       "      <th>28400</th>\n",
       "      <th>28401</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.622486</td>\n",
       "      <td>11.162004</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>12.788433</td>\n",
       "      <td>6.143456</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.876620</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.885589</td>\n",
       "      <td>3.914260</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.465420</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.973620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.398743</td>\n",
       "      <td>11.000080</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>12.845914</td>\n",
       "      <td>6.147482</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.484223</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.575025</td>\n",
       "      <td>4.236519</td>\n",
       "      <td>4.047825</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>4.176269</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.553796</td>\n",
       "      <td>4.967418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.692079</td>\n",
       "      <td>11.100175</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.171535</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>12.712544</td>\n",
       "      <td>5.583210</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.478171</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.992331</td>\n",
       "      <td>4.865538</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.488281</td>\n",
       "      <td>3.406285</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>6.676063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.613382</td>\n",
       "      <td>11.023209</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>12.750496</td>\n",
       "      <td>5.688023</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.464426</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.855643</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.905350</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>4.158393</td>\n",
       "      <td>4.433457</td>\n",
       "      <td>3.874214</td>\n",
       "      <td>5.981160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.482065</td>\n",
       "      <td>10.989851</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.992726</td>\n",
       "      <td>4.574745</td>\n",
       "      <td>12.878702</td>\n",
       "      <td>6.195418</td>\n",
       "      <td>4.177962</td>\n",
       "      <td>3.872567</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.879493</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>4.571869</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.982136</td>\n",
       "      <td>6.145585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>14.565031</td>\n",
       "      <td>11.699843</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>12.789212</td>\n",
       "      <td>6.504027</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>6.182912</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.338456</td>\n",
       "      <td>3.771718</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>6.100644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>14.624502</td>\n",
       "      <td>11.918757</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.292406</td>\n",
       "      <td>3.430485</td>\n",
       "      <td>10.728709</td>\n",
       "      <td>6.197159</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.089918</td>\n",
       "      <td>5.201608</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.790134</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>4.985474</td>\n",
       "      <td>4.444057</td>\n",
       "      <td>3.580523</td>\n",
       "      <td>6.301926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>14.585190</td>\n",
       "      <td>11.090112</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.674768</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>12.877485</td>\n",
       "      <td>6.326960</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.547342</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>4.064473</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.254152</td>\n",
       "      <td>5.964505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>14.449554</td>\n",
       "      <td>10.805855</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>12.660038</td>\n",
       "      <td>6.261395</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.125096</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.784260</td>\n",
       "      <td>3.644823</td>\n",
       "      <td>4.546974</td>\n",
       "      <td>3.427441</td>\n",
       "      <td>3.32</td>\n",
       "      <td>4.666265</td>\n",
       "      <td>3.888525</td>\n",
       "      <td>3.765754</td>\n",
       "      <td>5.452018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>14.439020</td>\n",
       "      <td>11.080826</td>\n",
       "      <td>4.152651</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>12.187504</td>\n",
       "      <td>6.154358</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.247009</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.671102</td>\n",
       "      <td>3.519157</td>\n",
       "      <td>4.771458</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>5.115644</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.410361</td>\n",
       "      <td>6.449961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 28402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0          1         2         3         4          5         6      \\\n",
       "0   14.622486  11.162004  3.320000  3.320000  3.320000  12.788433  6.143456   \n",
       "1   14.398743  11.000080  3.320000  3.320000  3.320000  12.845914  6.147482   \n",
       "2   14.692079  11.100175  3.320000  4.171535  3.320000  12.712544  5.583210   \n",
       "3   14.613382  11.023209  3.320000  3.320000  3.320000  12.750496  5.688023   \n",
       "4   14.482065  10.989851  3.320000  3.992726  4.574745  12.878702  6.195418   \n",
       "..        ...        ...       ...       ...       ...        ...       ...   \n",
       "56  14.565031  11.699843  3.320000  3.320000  3.320000  12.789212  6.504027   \n",
       "57  14.624502  11.918757  3.320000  4.292406  3.430485  10.728709  6.197159   \n",
       "58  14.585190  11.090112  3.320000  3.674768  3.320000  12.877485  6.326960   \n",
       "59  14.449554  10.805855  3.320000  3.320000  3.320000  12.660038  6.261395   \n",
       "60  14.439020  11.080826  4.152651  3.320000  3.320000  12.187504  6.154358   \n",
       "\n",
       "       7         8         9      ...  28392     28393     28394     28395  \\\n",
       "0   3.320000  4.876620  3.320000  ...   3.32  3.320000  3.885589  3.914260   \n",
       "1   3.320000  4.484223  3.320000  ...   3.32  3.575025  4.236519  4.047825   \n",
       "2   3.320000  3.478171  3.320000  ...   3.32  3.320000  3.992331  4.865538   \n",
       "3   3.320000  4.464426  3.320000  ...   3.32  3.855643  3.320000  4.905350   \n",
       "4   4.177962  3.872567  3.320000  ...   3.32  3.320000  3.320000  4.879493   \n",
       "..       ...       ...       ...  ...    ...       ...       ...       ...   \n",
       "56  3.320000  3.320000  6.182912  ...   3.32  3.320000  3.320000  4.338456   \n",
       "57  3.320000  4.089918  5.201608  ...   3.32  3.320000  3.320000  4.790134   \n",
       "58  3.320000  3.320000  3.320000  ...   3.32  3.320000  3.320000  4.547342   \n",
       "59  3.320000  4.125096  3.320000  ...   3.32  3.784260  3.644823  4.546974   \n",
       "60  3.320000  4.247009  3.320000  ...   3.32  3.671102  3.519157  4.771458   \n",
       "\n",
       "       28396  28397     28398     28399     28400     28401  \n",
       "0   3.320000   3.32  3.320000  4.465420  3.320000  4.973620  \n",
       "1   3.320000   3.32  4.176269  3.320000  4.553796  4.967418  \n",
       "2   3.320000   3.32  3.488281  3.406285  3.320000  6.676063  \n",
       "3   3.320000   3.32  4.158393  4.433457  3.874214  5.981160  \n",
       "4   3.320000   3.32  4.571869  3.320000  4.982136  6.145585  \n",
       "..       ...    ...       ...       ...       ...       ...  \n",
       "56  3.771718   3.32  3.320000  3.320000  3.320000  6.100644  \n",
       "57  3.320000   3.32  4.985474  4.444057  3.580523  6.301926  \n",
       "58  3.320000   3.32  4.064473  3.320000  4.254152  5.964505  \n",
       "59  3.427441   3.32  4.666265  3.888525  3.765754  5.452018  \n",
       "60  3.320000   3.32  5.115644  3.320000  3.410361  6.449961  \n",
       "\n",
       "[61 rows x 28402 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_expression_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diagnosis: healthy control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diagnosis: healthy control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diagnosis: healthy control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>diagnosis: healthy control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>diagnosis: healthy control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>omalizumab responder status: Responder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>omalizumab responder status: Responder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>omalizumab responder status: Responder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>omalizumab responder status: Responder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>omalizumab responder status: Responder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0\n",
       "0               diagnosis: healthy control\n",
       "1               diagnosis: healthy control\n",
       "2               diagnosis: healthy control\n",
       "3               diagnosis: healthy control\n",
       "4               diagnosis: healthy control\n",
       "..                                     ...\n",
       "56  omalizumab responder status: Responder\n",
       "57  omalizumab responder status: Responder\n",
       "58  omalizumab responder status: Responder\n",
       "59  omalizumab responder status: Responder\n",
       "60  omalizumab responder status: Responder\n",
       "\n",
       "[61 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 28402])\n",
      "torch.Size([40, 1])\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "labels_encoded = encoder.fit_transform(labels.values)\n",
    "labels_encoded_noncontrols = labels_encoded[labels_encoded!=0] - 1\n",
    "\n",
    "data_controls = gene_expression_matrix[labels_encoded==0]\n",
    "data = gene_expression_matrix[labels_encoded!=0]\n",
    "\n",
    "gene_signature = data_controls.mean(axis=0)\n",
    "data_scaled = data - gene_signature\n",
    "\n",
    "scaler = MinMaxScaler((0, 1))\n",
    "scaler.fit(data_scaled)\n",
    "data_normalized = scaler.transform(data_scaled)\n",
    "\n",
    "x_train = torch.FloatTensor(data_normalized)\n",
    "y_train = torch.FloatTensor(labels_encoded_noncontrols).unsqueeze(1)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train accuracy: 0.2250\n",
      "Epoch 1000: train accuracy: 0.7500\n",
      "Epoch 2000: train accuracy: 0.7500\n",
      "Epoch 3000: train accuracy: 0.7500\n",
      "Epoch 4000: train accuracy: 0.9500\n",
      "Epoch 5000: train accuracy: 0.9750\n",
      "Epoch 6000: train accuracy: 1.0000\n",
      "Epoch 7000: train accuracy: 1.0000\n",
      "Epoch 8000: train accuracy: 1.0000\n",
      "Epoch 9000: train accuracy: 1.0000\n",
      "Epoch 10000: train accuracy: 1.0000\n",
      "Epoch 11000: train accuracy: 1.0000\n",
      "Epoch 12000: train accuracy: 1.0000\n",
      "Epoch 13000: train accuracy: 1.0000\n",
      "Epoch 14000: train accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "layers = [\n",
    "    torch.nn.Linear(x_train.size(1), 10),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(10, 5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(5, 1),\n",
    "    torch.nn.Sigmoid(),\n",
    "]\n",
    "model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "model.train()\n",
    "need_pruning = True\n",
    "for epoch in range(15000):\n",
    "    # forward pass\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x_train)\n",
    "    # Compute Loss\n",
    "    loss = torch.nn.functional.mse_loss(y_pred, y_train)\n",
    "\n",
    "    for module in model.children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            loss += 0.01 * torch.norm(module.weight, 1)\n",
    "            loss += 0.01 * torch.norm(module.bias, 1)\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # compute accuracy\n",
    "    if epoch % 1000 == 0:\n",
    "        y_pred_d = (y_pred > 0.5)\n",
    "        accuracy = (y_pred_d.eq(y_train).sum(dim=1) == y_train.size(1)).sum().item() / y_train.size(0)\n",
    "        print(f'Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "        \n",
    "    if epoch > 8000 and need_pruning and epoch % 1000 == 0:\n",
    "        prune_features(model, 1, device)\n",
    "        need_pruning = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 1\n",
      "\tx=[0.94 0.31 0.   ... 0.26 0.8  0.68]\n",
      "\ty=[0.]\n",
      "\ty=[0.99]\n",
      "\tExplanation: ~feature0000006749 & ~feature0000010382 & ~feature0000013464 & feature0000013710 & feature0000022010 & ~feature0000025379 & ~feature0000026329\n",
      "\n",
      "Input 2\n",
      "\tx=[0.84 0.71 0.   ... 0.26 0.   0.62]\n",
      "\ty=[0.]\n",
      "\ty=[0.99]\n",
      "\tExplanation: ~feature0000006749 & ~feature0000010382 & feature0000013464 & ~feature0000013710 & ~feature0000022010 & ~feature0000025379 & ~feature0000026329\n",
      "\n",
      "Input 3\n",
      "\tx=[0.62 0.36 0.   ... 0.   0.   0.71]\n",
      "\ty=[0.]\n",
      "\ty=[0.99]\n",
      "\tExplanation: ~feature0000006749 & ~feature0000010382 & ~feature0000013464 & ~feature0000013710 & ~feature0000022010 & ~feature0000025379 & feature0000026329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2, suppress=True)\n",
    "outputs = []\n",
    "for i, (xin, yin) in enumerate(zip(x_train, y_train)):\n",
    "    model_reduced = get_reduced_model(model, xin.to(device)).to(device)\n",
    "    for module in model_reduced.children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            wa = module.weight.cpu().detach().numpy()\n",
    "            break\n",
    "    output = model_reduced(xin)\n",
    "    \n",
    "    pred_class = torch.argmax(output)\n",
    "    true_class = torch.argmax(y_train[i])\n",
    "\n",
    "    # generate local explanation only if the prediction is correct\n",
    "    if pred_class.eq(true_class):\n",
    "        local_explanation = fol.relunn.explain_local(model.to(device), x_train, y_train, xin, yin, device=device)\n",
    "        print(f'Input {(i+1)}')\n",
    "        print(f'\\tx={xin.cpu().detach().numpy()}')\n",
    "        print(f'\\ty={y_train[i].cpu().detach().numpy()}')\n",
    "        print(f'\\ty={output.cpu().detach().numpy()}')\n",
    "        #print(f'\\tw={wa}')\n",
    "        print(f'\\tExplanation: {local_explanation}')\n",
    "        print()\n",
    "    outputs.append(output)\n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine local explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of when using the formula \"(feature0000010382 & feature0000013710 & feature0000026329 & ~feature0000006749 & ~feature0000013464 & ~feature0000022010) | (feature0000013464 & ~feature0000006749 & ~feature0000010382 & ~feature0000013710 & ~feature0000022010 & ~feature0000025379 & ~feature0000026329)\": 0.3750\n"
     ]
    }
   ],
   "source": [
    "global_explanation, predictions, counter = fol.combine_local_explanations(model, \n",
    "                                                                          x=x_train, y=y_train, \n",
    "                                                                          target_class=0,\n",
    "                                                                          topk_explanations=3,\n",
    "                                                                          device=device)\n",
    "\n",
    "ynp = y_train.cpu().detach().numpy()[:, 0]\n",
    "accuracy = np.sum(predictions == ynp) / len(ynp)\n",
    "print(f'Accuracy of when using the formula \"{global_explanation}\": {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 - Global explanation: \"(feature0000006749 & feature0000010382 & feature0000013710) | (feature0000006749 & feature0000010382 & feature0000025379) | (feature0000006749 & feature0000010382 & feature0000026329) | (feature0000006749 & feature0000013710 & feature0000025379) | (feature0000006749 & feature0000013710 & feature0000026329) | (feature0000006749 & feature0000025379 & feature0000026329) | (feature0000010382 & feature0000013710 & feature0000025379) | (feature0000010382 & feature0000013710 & feature0000026329) | (feature0000010382 & feature0000025379 & feature0000026329) | (feature0000013710 & feature0000025379 & feature0000026329) | (feature0000006749 & feature0000010382 & ~feature0000013464) | (feature0000006749 & feature0000010382 & ~feature0000022010) | (feature0000006749 & feature0000013710 & ~feature0000013464) | (feature0000006749 & feature0000013710 & ~feature0000022010) | (feature0000006749 & feature0000025379 & ~feature0000022010) | (feature0000006749 & feature0000026329 & ~feature0000022010) | (feature0000010382 & feature0000013710 & ~feature0000013464) | (feature0000010382 & feature0000013710 & ~feature0000022010) | (feature0000010382 & feature0000025379 & ~feature0000022010) | (feature0000010382 & feature0000026329 & ~feature0000022010) | (feature0000013710 & feature0000025379 & ~feature0000022010) | (feature0000013710 & feature0000026329 & ~feature0000022010) | (feature0000025379 & feature0000026329 & ~feature0000022010) | (feature0000006749 & ~feature0000013464 & ~feature0000022010) | (feature0000010382 & ~feature0000013464 & ~feature0000022010) | (feature0000013710 & ~feature0000013464 & ~feature0000022010)\" - Accuracy: 0.9750\n"
     ]
    }
   ],
   "source": [
    "global_explanation = fol.relunn.explain_global(model, n_classes=1, target_class=0, device=device)\n",
    "explanation = fol.relunn.explain_global(model, n_classes=1, target_class=0, device=device)\n",
    "if explanation not in ['False', 'True', 'The formula is too complex!']:\n",
    "    accuracy, _ = fol.relunn.test_explanation(explanation, target_class=0, x=x_train.cpu(), y=y_train.cpu())\n",
    "    print(f'Class {0} - Global explanation: \"{global_explanation}\" - Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6749</th>\n",
       "      <td>ILMN_1708983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10382</th>\n",
       "      <td>ILMN_1745049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13464</th>\n",
       "      <td>ILMN_1775520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13710</th>\n",
       "      <td>ILMN_1777811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22010</th>\n",
       "      <td>ILMN_2241168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25379</th>\n",
       "      <td>ILMN_3228700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26329</th>\n",
       "      <td>ILMN_3243714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "6749   ILMN_1708983\n",
       "10382  ILMN_1745049\n",
       "13464  ILMN_1775520\n",
       "13710  ILMN_1777811\n",
       "22010  ILMN_2241168\n",
       "25379  ILMN_3228700\n",
       "26329  ILMN_3243714"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = collect_parameters(model, device)\n",
    "feature_weights = w[0]\n",
    "feature_used_bool = np.sum(np.abs(feature_weights), axis=0) > 0\n",
    "feature_used = np.nonzero(feature_used_bool)[0]\n",
    "genes.iloc[feature_used]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ILMN_3286286, ILMN_1775520, ILMN_1656849, ILMN_1781198, ILMN_1665457"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
